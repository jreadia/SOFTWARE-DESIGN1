{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configuration ---\n",
    "DATASET_DIR = \"Rust_Dataset\"\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_CLASSES = 4\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Device (CPU/GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9618f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Setup\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(NORM_MEAN, NORM_STD)\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(NORM_MEAN, NORM_STD)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(NORM_MEAN, NORM_STD)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATASET_DIR, x), data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=(x == 'train'), num_workers=2)\n",
    "               for x in ['train', 'valid']}\n",
    "\n",
    "test_loader = DataLoader(image_datasets['test'], batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training samples: {len(image_datasets['train'])}\")\n",
    "print(f\"Validation samples: {len(image_datasets['valid'])}\")\n",
    "print(f\"Test samples: {len(image_datasets['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129579ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Construction\n",
    "model = models.densenet121(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# DenseNet121 uses 'classifier' as the final fully connected layer\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"Model loaded and configured successfully!\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Validation Loss and Accuracy\n",
    "print(\"Starting training...\")\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(image_datasets['train'])\n",
    "    epoch_acc = correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    \n",
    "    # Validation loss and accuracy\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in dataloaders['valid']:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_running_loss += val_loss.item() * val_inputs.size(0)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "    val_epoch_loss = val_running_loss / len(image_datasets['valid'])\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss:.4f} - Val Loss: {val_epoch_loss:.4f} - Acc: {epoch_acc:.4f} - Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Loss and Accuracy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(range(1, EPOCHS+1), train_losses, label='Training Loss', linewidth=2)\n",
    "ax1.plot(range(1, EPOCHS+1), val_losses, label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epochs', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(range(1, EPOCHS+1), train_accuracies, label='Train', linewidth=2)\n",
    "ax2.plot(range(1, EPOCHS+1), val_accuracies, label='Test', linewidth=2)\n",
    "ax2.set_xlabel('epoch', fontsize=12)\n",
    "ax2.set_ylabel('accuracy', fontsize=12)\n",
    "ax2.set_title('model accuracy', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Final Training Accuracy: {train_accuracies[-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {val_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f79689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(model, dataloader, device):\n",
    "    \"\"\"Calculates Mean Average Precision using 'scikit-learn'.\"\"\"\n",
    "    try:\n",
    "        from sklearn.metrics import average_precision_score\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        \n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = torch.softmax(model(inputs), dim=1)\n",
    "                all_preds.append(outputs.cpu().numpy())\n",
    "                all_labels.append(labels.numpy())\n",
    "        \n",
    "        y_pred_probs = np.concatenate(all_preds)\n",
    "        y_true = np.concatenate(all_labels)\n",
    "        y_true_bin = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
    "        return average_precision_score(y_true_bin, y_pred_probs, average=\"macro\")\n",
    "    except ImportError:\n",
    "        print(\"[WARN] 'scikit-learn' not installed. Skipping Performance (mAP) metric.\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_code_metrics():\n",
    "    \"\"\"Calculates code complexity metrics using 'radon'.\"\"\"\n",
    "    try:\n",
    "        import radon.complexity as cc\n",
    "        import radon.metrics as mi\n",
    "        # Read the original .py file for analysis\n",
    "        py_file = 'densenet_121.py'\n",
    "        if os.path.exists(py_file):\n",
    "            with open(py_file, 'r') as f:\n",
    "                code = f.read()\n",
    "            complexity_data = cc.cc_visit(code)\n",
    "            avg_cc = np.mean([item.complexity for item in complexity_data]) if complexity_data else 0\n",
    "            maintainability_index = mi.mi_visit(code, multi=False)\n",
    "            return avg_cc, maintainability_index\n",
    "        else:\n",
    "            print(\"[WARN] Original .py file not found for code metrics.\")\n",
    "            return 0, 0\n",
    "    except ImportError:\n",
    "        print(\"[WARN] 'radon' not installed. Skipping Functionality & Compatibility metrics.\")\n",
    "        return 0, 0\n",
    "\n",
    "print(\"Metric functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2171c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Metrics\n",
    "print(\"Calculating metrics...\")\n",
    "\n",
    "# A. Manufacturability\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# B. Efficiency\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "steps_to_test = 50\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(test_loader):\n",
    "        if i >= steps_to_test: break\n",
    "        inputs = inputs.to(device)\n",
    "        _ = model(inputs)\n",
    "end_time = time.time()\n",
    "avg_inference_time_ms = ((end_time - start_time) / steps_to_test) * 1000\n",
    "\n",
    "# C. Performance (mAP)\n",
    "mAP = calculate_map(model, test_loader, device)\n",
    "\n",
    "# D & E. Functionality & Compatibility\n",
    "avg_cc, maint_index = calculate_code_metrics()\n",
    "\n",
    "print(\"Metrics calculated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RUST DETECTION MODEL: DENSENET121 (PyTorch)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"1. Manufacturability (Model Complexity): {total_params:,} parameters\")\n",
    "print(f\"2. Efficiency (Avg Inference Time):      {avg_inference_time_ms:.2f} ms/image\")\n",
    "print(f\"3. Performance (Mean Average Precision): {mAP:.4f}\")\n",
    "print(f\"4. Functionality (Cyclomatic Complexity):{avg_cc:.2f} (Avg per block)\")\n",
    "print(f\"5. Compatibility (Maintainability Index):{maint_index:.2f} (Scale 0-100)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'rust_densenet121.pth')\n",
    "print(\"Model saved to rust_densenet121.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
